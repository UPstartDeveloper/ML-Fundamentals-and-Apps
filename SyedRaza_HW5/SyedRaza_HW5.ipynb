{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102a0758",
   "metadata": {},
   "source": [
    "## <center> CS559 Machine Learning: Fundamentals and Applications</center>\n",
    "<center> Fall 2022 HW5</center>\n",
    "<center>Due: 12/16/2022 Friday 11:59 PM </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2cb96",
   "metadata": {},
   "source": [
    "Homework assignments will be done individually: each student must hand in their own answers. Use of partial or entire solutions obtained from others or online is strictly prohibited. Electronic submission on Canvas is mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11037a17",
   "metadata": {},
   "source": [
    "# Graphical Models (30 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce17fb",
   "metadata": {},
   "source": [
    "Consider following tables:\n",
    "\n",
    "let C = random Bernoulli var\n",
    "\n",
    "||p(C)|\n",
    "|----|----|\n",
    "|F|0.65|\n",
    "|T|0.35|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491f1e5",
   "metadata": {},
   "source": [
    "let R and S also = random Bernoulli vars, conditional on C\n",
    "\n",
    "|C|p(S=F)|p(S=T)|p(R=F)|p(R=T)|\n",
    "|--|--|--|--|--|\n",
    "|F|0.7|0.3|0.8|0.2|\n",
    "|T|0.8|0.2|0.2|0.8|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8519c7",
   "metadata": {},
   "source": [
    "let W = random Bernoulli vars, conditional on R and S\n",
    "\n",
    "|S|R|p(W=T)|p(W=F)|\n",
    "|-|-|---|---|\n",
    "|F|F|0.96|0.04|\n",
    "|T|F|0.15|0.85|\n",
    "|F|T|0.17|0.83|\n",
    "|T|T|0.02|0.98|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8acf9cb8",
   "metadata": {},
   "source": [
    "## Part A\n",
    "(5 pts) Using pgmpy, draw a conditional directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6fafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from daft import PGM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pgmpy.models import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb32324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pgm_to_pgmpy(pgm):\n",
    "    \"\"\"\n",
    "    Takes a Daft PGM object and converts it to a pgmpy BayesianModel.\n",
    "\n",
    "    (Function taken from class notebook).\n",
    "    \"\"\"\n",
    "    edges = [(edge.node1.name, edge.node2.name) for edge in pgm._edges]\n",
    "    model = BayesianNetwork(edges)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2a992c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAFOCAYAAADpU/RpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoZUlEQVR4nO3deViU5f4G8HsGcEARlcwVEQUlEdchT1qxKGYntzrlkuaaZlBq6TnHk79K6zplWV2eLCQTtzSttGOaC3QsyQU3RhE1OW5IGgkqLuzDzDy/PzxMgZrMzDvzvvPO/fkrJud5vlxNt889yzsaIYQAERHVmVbuAYiI3A2Dk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRt5yD0COs1gsKCgoQFlZGUwmE3Q6HZo0aYJGjRrJPRqRKjE43VB5eTm2bNmC/fv3w2Aw4NChQ7h+/fotf659+/bQ6/XQ6/WIj4+HXq+XYVoi9dEIIYTcQ1DdnDlzBp988gmWLVuGoqIitG3b1hqMnTt3RsOGDeHt7Y3KykpcvHgRhw4dgsFgwOHDh1FSUoL7778fiYmJGDFiBPz8/OT+dYjcFoPTDRQWFmLatGn48ssv0aRJE0ycOBHPP/88wsLC6nR/s9mMbdu2ISkpCampqQgMDMS8efMwefJkaDQaJ09PpD4MToVbt24dEhMTAQDz5s3D6NGjHTotnjlzBm+//TaWLVuG+Ph4pKSkoG3btlKNS+QR+Kq6QlVUVGDUqFEYPnw4YmJicPz4cUyaNMnhih0aGoqlS5ciNTUVOTk56NKlC9avXy/R1ESegcGpQCUlJRg4cCA2bNiAtWvXYv369WjWrJmkewwYMADHjh3DY489huHDhyMlJUXS9YnUjK+qK0xFRQUef/xxHDx4EGlpaYiOjnbaXo0aNcKaNWsQGBiIyZMnQ6fTYcyYMU7bj0gtGJwKM2XKFOzZswepqalODc1qWq0WSUlJMBqNmDBhAtq2beuSfYncGV8cUpCNGzfi8ccfx4oVKzBu3DiX7m02mxEbG4v8/HxkZ2ejQYMGLt2fyJ0wOBWiqKgIERERuP/++7Fp0yZZ3iZ0+vRpdO3aFZMmTcLChQtdvj+Ru+CLQwoxc+ZMVFZWYvHixbK9tzIsLAzz5s3DRx99hIyMDFlmIHIHPHEqQH5+PoKDg/HBBx9g+vTpss5isVjQtWtXhIeH4+uvv5Z1FiKl4olTAZYsWQJfX1+MHz9e7lGg1WqRmJiIjRs34sKFC3KPQ6RIDE6ZVVVV4dNPP8UzzzyjmKsZPfPMM/Dz88Onn34q9yhEisTglFl6ejry8/MxZcoUuUexCggIwOjRo7F69Wq5RyFSJAanzA4ePIhGjRqhe/fuDq1z8eJFTJ06Fe3bt4dOp0ObNm0wePBgfP/993atFxsbi9zcXFy+fNmhuYjUiMEpM4PBAL1e79Ar6efOnYNer8cPP/yA+fPn4+jRo0hNTUVcXBxeeOEFu9asvnanwWCwey4iteInh2SWmZmJESNGOLRGYmIiNBoNDhw4UOON6507d8bEiRPtWjM0NBQBAQEwGAwYMGCAQ/MRqQ1PnDIyGo34+eefERERYfcaRUVFSE1NxQsvvHDbT/s0btzYrnW1Wi06deqEU6dO2T0bkVoxOGVUVlYGAA59vPH06dMQQuC+++6TaiyrBg0aoLy8XPJ1idwdg1NGZrMZAODl5WX3GtWfX3DGp428vb1hMpkkX5fI3TE4ZeTr6wvg5qXk7NWhQwdoNBqcOHFCqrGsysvL+d1ERLfB4JSRn58fGjRogPz8fLvXCAwMxIABA5CUlITS0tJb/v21a9fsXjs/Px9Nmza1+/5EasXglJFWq0X37t0dfsvPokWLYDab0atXL3z99dc4deoUTpw4gYULF6J37952rXnt2jWcOXMGPXv2dGg2IjXi25FkptfrsW3bNofWaNeuHQ4dOoS33noLM2fOxK+//op7770Xer0eycnJdq156NAh63xEVBOvjiSzVatWYezYsSgqKkKTJk3kHsdq/vz5ePPNN3H9+nWHXrwiUiNWdZn17dsXXl5e+OKLL+QexUoIgc8//xzx8fEMTaLbYHDKrHXr1hg6dCgWLVoEpRz+MzIykJ2dbf0+dyKqicGpAAkJCTh27Bh2794t9ygAbr7YFBYWhvj4eLlHIVIkPsepABaLBREREWjdujW2b98u21dnAMCxY8fQs2dPvPPOO5gxY4ZscxApGYNTIb777jsMGDAAn3zyiWzX5jSZTOjduzfKyspgMBisb9AnoppY1RXikUceweTJk/HXv/4V586dk2WG9957D4cOHcLy5csZmkR/gCdOBblx4wYiIyMRFBSE7du3o379+i7be9euXYiPj8fLL7+Md955x2X7ErkjBqfC7Nu3D/369UN0dDQ2bNjgkpNfZmYm+vXrh6ioKGzduhU6nc7pexK5M1Z1hXnggQewceNGpKenY+DAgSguLnbqfj/++CP69u2LiIgIfPPNNwxNojpgcCpQfHw8UlNTcfDgQfTo0QM7d+6UfA+j0Yg5c+YgPj4evXr1wn/+8x80bNhQ8n2I1IjBqVAxMTEwGAwoKipCTEwMpk+ffturH9kjKysLPXr0wJtvvonnnnsOW7duhb+/vyRrE3kCBqeCFRYW4urVqwCATz/9FO3atcPs2bORl5dn81oWiwVpaWkYOnQo9Ho9qqqqANx8s3u9evUknZtI7RicCmWxWPDQQw8BAPLy8nD8+HE8/fTTSEpKQvv27TF48GD861//wq5du1BSUnLL/YUQyMvLw7///W/Mnj0b4eHhePTRR5GXl4fk5GQcO3YMAwcOBAA888wzLv3diNwdX1VXqAceeAD79+/HtGnT8OGHH1pvLy0txdq1a7FixQoYDAZUVFRAo9EgJCQE/v7+8PHxQUVFBQoKCnDlyhUAQMuWLdGvXz8kJCSgd+/e1k8mCSGg1d78uzMnJwfh4eGu/0WJ3BCDU4H27NljPW3+0X8ek8mEEydOIDMzEzk5OSgrK0NVVRX8/PwQGBiIHj16QK/Xo2XLlndco/r5zrvtRUS/YXAqjMVisV7KLS8vD8HBwU7fc9CgQdiyZQtGjx6N1atXO30/InfH5zgVpk+fPgCAadOmuSQ0AeDbb78FAHz++ef473//65I9idwZT5wKUteK7gys7ER1xxOnQtR+Fd3VunfvzlfZieqIwakQclT02ljZieqGVV0B5KzotbGyE90dT5wyk7ui18bKTnR3DE6ZKaGi18bKTvTHWNVlpKSKXhsrO9Gd8cQpE6VV9NpY2YnujMEpEyVW9NpY2Yluj1VdBkqu6LWxshPdiidOF1N6Ra+NlZ3oVgxOF3OHil4bKztRTazqLuROFb02Vnai3/DE6SLuVtFrY2Un+g2D00XcsaLXxspOdBOrugu4c0WvjZWdiCdOp3P3il4bKzsRg9Pp1FDRa2NlJ0/Hqu5EaqrotbGykyfjidNJ1FbRa2NlJ0/G4HQSNVb02ljZyVOxqjuBmit6bazs5Il44pSY2it6bazs5IkYnBLzhIpeGys7eRpWdQl5UkWvjZWdPAlPnBLxtIpeGys7eRIGp0Q8saLXxspOnoJVXQKeXNFrY2UnT8ATp4M8vaLXxspOnoDB6SBW9FuxspPasao7gBX9zljZSc144rQTK/of+31lHzNmjMzTEEmLwWknVvS7q67sq1evZmUnVWFVtwMret2xspMa8cRpI1Z027CykxoxOG3Eim47VnZSG1Z1G7Ci24+VndSEJ846YkV3DCs7qQmDs45Y0R3Hyk5qwapeB6zo0mFlJzXgifMuWNGlxcpOasDgvAtWdOmxspO7Y1X/A6zozsPKTu6MJ847YEV3LlZ2cmcMzjtgRXc+VnZyV6zqt8GK7jqs7OSOeOKshRXdtVjZyR0xOGthRXc9VnZyN6zqv8OKLh9WdnInPHH+Dyu6vFjZyZ0wOP+HFV1+rOzkLljVwYquJKzs5A48/sTJiq4srOzkDjw+OFnRlYeVnZTOo6s6K7pysbKTknnsiZMVXdlY2UnJPDY4WdGVj5WdlMojqzoruvtgZScl8rgTJyu6e2FlJyXyuOBkRXc/rOykNB5V1VnR3RcrOymJx5w4WdHdGys7KYnHBCcruvtjZSel8IiqzoquHqzspASqP3GyoqsLKzspgeqDkxVdfVjZSW6qruqs6OrFyk5yUu2JkxVd3VjZSU6qDU5WdPVjZSe5qCo4N2/ejC5dumDmzJnYv38/AODDDz+UeSpyFo1Gg8OHDwMA7rvvPowZMwYxMTEoLS2VeTJSO1U9x9m9e3ccOXLE+vPevXvxwAMPyDgRuULLli1x8eJF689LlizBpEmTZJyI1E41J86DBw/WCE0AePTRR2GxWGSaiFzhq6++qhGaGo0GCxcu5AtG5FSqCc6kpCR4e3tbf/by8kKLFi1gNptlnIqcLTAwEFrtbw9jIQSOHj2KAwcOyDgVqZ0qgrOoqAhr166FyWQCcDM0w8LCsHPnTvj4+Mg8HTlTfHw8vvjiixrh6e3tjUWLFsk4Famd4oKzqqoKJSUlMBqNda5bK1asQFVVFYCaodmsWTNnjkoKMWzYsBrhaTKZsHbtWly5cqVO9xdCoLy8HGVlZXxqh+pE1heHTp8+jV27dsFgMMBgMODIkSMoLy+3/vt69eohMjISer0eer0effr0QZcuXWqsYbFYEBYWhtzcXIamh1u3bh1GjhwJi8UCjUaD9957DzNnzqzxZyoqKpCeng6DwYDMzEwYDAacP3++xp9p2bIl9Ho9oqKioNfrERsbC39/f1f+KqRwLg/OqqoqbNq0CYsWLcIPP/wAjUaD8PBw6PV69OjRA/fccw90Oh2MRiOuXbuGI0eOwGAw4Pjx4zCbzejVqxcSExMxfPhw+Pn5Yfv27ejfvz8AIDw8nKHp4X4fniEhIThz5gy0Wi3OnDmDxYsXY9myZbhy5QoaN25s/Qs5LCwM9evXBwCUl5cjNzfX+pf55cuXERAQgHHjxiEhIQGdOnWS+TckRRAuYrFYREpKimjVqpUAIB566CGxZs0acePGjTrdv6ysTGzcuFE8+uijAoAIDAwU7777rhg8eLAAIMLDw0VBQYGTfwtyB1999ZXQarUCgPjss8/EkCFDhEajEU2aNBEzZ84Ux48fFxaL5a7rWCwWcerUKfF///d/olmzZgKAiI+PFzk5OS74LUjJXBKcP//8szXwRo8eLbKyshxa79SpU+LFF18UWq1WaDQaERISwtCkGr788kuh0WiEj4+PCAoKEsuWLRNlZWV2r1dZWSnWrFkjOnToIHx9fcX7778vTCaThBOTO3F6cH755ZciICBAtGrVSmzZskXStTMyMkRISIjQ6XRi4cKFkq5N7uvy5cuif//+AoCYMGGCuHbtmmRrl5aWipdfflloNBrRp08fceHCBcnWJvfh1OBMSkoSAMTIkSPF1atXnbJHWVmZmDZtmgAgZs+eXacKRuqVn58vOnfuLJo2bSpSU1Odts+uXbtEUFCQaNeunThz5ozT9iFlclpwLl68WAAQL730kjCbzc7axur9998XAMSrr77q9L1ImQoLC8V9990ngoKCxIkTJ5y+X15enujYsaMIDg4WeXl5Tt+PlMMpwbl582ah0WjE1KlTXXoCnD9/vgAgkpOTXbYnKYPRaBT333+/aN68uTh58qTL9r1w4YIICQkR4eHhoqSkxGX7krwkD84rV66IFi1aiIEDB7rkpFnblClTRP369cXp06ddvjfJZ+7cucLLy0scOHDA5Xvn5OQIPz8/MXXqVJfvTfKQPDhHjx4tGjduLH755Repl66T4uJiERISIqKjo2UJbnK9rKws4e3tLevTNAsWLBAARHp6umwzkOtI+gb4zZs3Y/Dgwfjss89kvSr3jh070LdvXyQlJSExMVG2Ocj5zGYzoqKiYDabkZmZiXr16skyh8ViQUxMDPLz83H8+HH4+vrKMge5hqTB2adPH+h0OusnguQ0duxYpKenWz+KSeq0ZcsWDBo0CLt378aDDz4o6yw5OTno1KkTVq5cibFjx8o6CzmXZMF5+PBh9OzZExs2bMDjjz8uxZIOMRgMiIqKwsaNGzFkyBC5xyEneeyxx3Dp0iUcPHhQ7lEA3LwG7NWrV63fQEDqJNnVkRYtWoSgoCAMGjRIqiUdotfr0atXL15eTMXOnDmD1NRURT0dk5iYiAMHDiAzM1PuUciJJAlOo9GINWvWYPLkyTUuJiy3hIQEpKWlIT8/X+5RyAlWrVqFgIAAjBgxQu5RrAYOHIg2bdpgxYoVco9CTiRJcB47dgxlZWXWqxTZY/z48dBoNNBoNPD29kZwcDASEhJw9epVu9eMj48HAF4NXKX279+Phx56yHplI3sVFhZiypQpCA4Ohk6nQ4sWLTBgwADs3bvX5rW8vLwQFxfHqq5ykgRnZmYmtFotunXr5tA6jz76KH799VecO3cOKSkp+Pbbbx2qYa1bt0bz5s1hMBgcmouURwiBzMxMREVFObzWk08+iSNHjmDlypU4efIkNm3ahNjYWBQVFdm1XlRUFLKzs2E0Gh2ejZRJkl5tMBgQERHh8N/81X/bA0BQUBBGjBjhUOXRaDTQ6/UMThU6f/48Ll++DL1e79A6165dw+7du5Geno6YmBgAQNu2bdGrVy+719Tr9TAajTh+/Dh69Ojh0HykTJKcOHNycm65Mrujzp49i9TUVIe/M6hLly44ceKERFORUuTk5ACAw487f39/+Pv745tvvkFlZaUUo1ln4uNOvSQJztLSUjRs2NDhdTZv3gx/f3/4+fkhNDQUP/30E2bNmuXQmg0bNkRZWZnDs5GylJaWAoDDjztvb2+sWLECK1euROPGjfHggw9i9uzZyM7OtnvN6q/Z4ONOvSQJTpPJJMmr6XFxccjKysL+/fsxdepUDBgwAFOnTnVoTR8fH+sXuZF6/P4bTR315JNPIj8/H5s2bcKAAQOQnp6Onj172v00UfULnHzcqZckwanT6SSpOQ0aNEBYWBi6du2KhQsXorKyEm+88YZDa1ZUVPDjbyqk0+kAQLIXYHx9fdG/f3+8/vrryMjIwPjx4zFnzhy71jKbzTCZTHzcqZgkwdmkSRMUFhZKsVQNc+bMwfvvv+/Q+zALCwvRuHFj6YYiRWjSpAkAOOVxBwARERHWpwNsVT0TH3fqJUlwdu/eHYcOHZJiqRpiY2PRuXNnvP3223avcejQIb6yqUJdu3YFAIcfd1euXEHfvn2xevVqZGdnIzc3F+vWrcP8+fMxdOhQu9asnomPO/WSJDijoqLwyy+/oKCgQIrlapgxYwaWLFlyy3df14XJZEJWVpbDb1kh5WnUqBE6duzo8Ecb/f398ac//QkLFixAdHQ0IiMj8dprr2Hy5Mn4+OOP7VozMzMTgYGBaNu2rUOzkXJJcpGP3NxctG/fHps3b8bAgQOlmEsS2dnZ6NatG3788UdER0fLPQ5JbNSoUTh37hwyMjLkHqWGwYMHw2g0Ii0tTe5RyEkkOXGGhIQgJCQE69atk2I5yaxbtw4NGzbkiVOl+vbti/379yMvL0/uUayKioqwfft2xMXFyT0KOZEkwanRaPD888/jiy++wJUrV6RY0mFGoxFLlizB2LFj0aBBA7nHIScYOXIk/P398emnn8o9itWKFStgNpsxceJEuUchJ5LssnITJ06EEALLly+XakmHbNiwAQUFBUhISJB7FHISf39/jBs3DikpKZJ96scRFosFycnJGDZsGJo1ayb3OOREkgXnvffeixEjRuDDDz9EcXGxVMvaxWQy4d1330V0dDQ6d+4s6yzkXImJiSgsLERKSorco2DdunU4ffq0oq4PSk4i5RcYnT17VjRo0EA8//zzUi5rs7feektotVqxf/9+Wecg15g8ebLw9/cXubm5ss1QWFgo7r33XvGXv/zFpV+JTfKQ/Fsuk5KSBACxfft2qZeuk6NHjwofHx8xa9YsWfYn17t+/bpo06aN6Nevn2yhNWzYMHHPPfeIixcvyrI/uZbkwWk2m0VcXJxo06aNyM/Pl3r5P3Tjxg3RvXt30alTJ1FeXu7SvUleaWlpAoCYP3++y/detmyZACDWrl3r8r1JHpIHpxBC5OXlidatW4vIyEhx+fJlZ2xxi7KyMhEXFycCAgJEVlaWS/YkZfnHP/4hAIhly5a5bM8NGzYILy8vMWnSJFZ0D+KU4BRCiJ9++kk0bdpUREZGOv3kef36dREdHS3q168vdu7c6dS9SLksFouYMmWK0Gg0Iikpyen7rVmzRnh7e4vhw4cLk8nk9P1IOZwWnEIIceLECREUFCRatmwpNm/e7JQ99uzZIzp27CgaN24s9uzZ45Q9yH2YzWbx0ksvCQBi4sSJ4urVq5LvUVpaKqZPny40Go0YN26cqKqqknwPUjanBqcQQvzyyy/iscceEwDE2LFjRVFRkSTrlpWViRkzZggAIjQ0VOTk5EiyLrk/i8UiUlJShJeXl2jWrJnYunWrZGvv3LlThIaGCj8/P7FgwQJhNpslW5vch9ODU4ibD+Tly5eLRo0aiaZNm4pXXnlFnDt3zq61CgoKxNtvvy3atGkjdDqdACAAiOLiYomnJnc2Z84cAUA0aNBAABCPPPKI2Lhxo12V2mw2i7S0NDF06FCh0WjEgw8+KE6ePOmEqclduCQ4q50/f15MnTpVBAQECK1WK4YMGSKWLl0qsrKyhNFovO19TCaT+Omnn8SqVavEqFGjhI+Pj/D19RUTJkwQOTk5YsWKFdbwJBJCiIsXL1ofE0ajUaxZs0b06tVLABDBwcHi9ddfF6mpqeLSpUt3XKOoqEhs375d/POf/xRhYWECgOjatatYsmQJn88kIcnVkWxVUlKCNWvWYPHixTh8+DCEEPD19UVkZCTuuece6HQ6GI1GXL9+HdnZ2dYLynbq1AmTJk3C+PHjERgYaF1Pq9VCCIGlS5fyM8IEjUYDAEhLS8MjjzxivT0zMxPJycn4+uuvcf36dQBAcHAwOnToAD8/PwBAeXk5cnNzcfbsWQA3v5Vg6NChSExMRJ8+faxrk2eTJTh/r7i4GFlZWTAYDDhy5Ahu3LiByspK1KtXD/7+/oiMjIRer0fPnj2tV/2urbS01PoFWcXFxdZ/Js8zd+5cvPHGGwgLC8OpU6du+2csFgvOnDkDg8EAg8GAn3/+GRUVFRBCwM/PD61atYJer4der0fHjh0l+V4jUhfZg1MqK1euxPjx4wEAKvmVyEYFBQVo0aIFAKCqqkqSLxAkuh3JLvIht3Hjxllr1LJly2SehuRQHZppaWkMTXIq1QQnAOtVmZ599lmUlJTIPA250ty5cwEAYWFhNZ7XJHIG1VT1aqzsnocVnVxNVSdOgJXdE7Gik6upLjgBVnZPwopOclBdVa/Gyq5+rOgkF1WeOAFWdk/Aik5yUW1wAqzsasaKTnJSbVWvxsquPqzoJDdVnzgBVnY1YkUnuak+OAFWdjVhRSclUH1Vr8bK7v5Y0UkpPOLECbCyqwErOimFxwQnwMruzljRSUk8pqpXY2V3P6zopDQedeIEWNndESs6KY3HBSfAyu5OWNFJiTyuqldjZVc+VnRSKo88cQKs7O6AFZ2UymODE2BlVzJWdFIyj63q1VjZlYcVnZTOo0+cACu7ErGik9J5fHACrOxKwopO7sDjq3o1Vnb5saKTu+CJ839Y2eXHik7ugsH5O6zs8mFFJ3fCql4LK7vrsaKTu+GJsxZWdtdjRSd3w+C8DVZ212FFJ3fEqn4HrOzOx4pO7oonzjtgZXc+VnRyVwzOP8DK7jys6OTOWNXvgpVdeqzo5O544ryL31f2pUuXyjyNOrCik7tjcNZBdWWfNGkSK7uDWNFJDVjV64iV3XGs6KQWPHHW0bhx46z/zMpuH1Z0UgsGpw2qazoru+1Y0UlNWNVtxMpuO1Z0UhueOG3Eym47VnRSGwanHVjZ644VndSIVd1OrOx3x4pOasUTp51Y2e+OFZ3UisHpAFb2O2NFJzVjVXcQK/utWNFJ7XjidBAr+61Y0UntGJwSYGX/DSs6eQJWdYmwsrOik+fgiVMirOys6OQ5GJwS8uTKzopOnoRVXWKeWNlZ0cnT8MQpMU+s7Kzo5GkYnE7gSZWdFZ08Eau6k3hCZWdFJ0/FE6eTeEJlZ0UnT8XgdCI1V3ZWdPJkrOpOpsbKzopOno4nTidTY2VnRSdPx+B0ATVVdlZ0IlZ1l1FDZWdFJ7qJJ04XUUNlZ0UnuonB6ULuXNlZ0Yl+w6ruYu5Y2VnRiWriidPF3LGys6IT1cTglIE7VXZWdKJbsarLxB0qOys60e3xxCkTd6jsrOhEt8fglJGSKzsrOtGdsarLTImVnRWd6I/xxCkzJVZ2VnSiP8b/KxSgpKQE/v7+mDRpEgBgw4YN+OCDDxAeHu6yGRYvXozvvvsOAQEBAFjRif4Iq7pCzJ8/H7NmzQIAaDQaTJw4ESkpKS7Z+/r162jRogUqKiqstxmNRvj4+LhkfyJ3w6quAIWFhXj77betPwsh8Pnnn+PatWsu2X/VqlWorKyscVv16ZeIbsXgVACj0Yiqqipotb/956isrMRnn33m9L2FEPjoo49qvDCl1WpRVlbm9L2J3BWDUwGCgoKwfft2+Pr61gjP2oHmDDt37sTJkyetP2u1WsTExGDlypVO3ZfInTE4FaJ37941wlMIgdOnTyM9Pd2p+y5atMj6ynl1aG7evBn169d36r5E7owvDinM3r17ER8fb32h5oknnsD69etv+XMXLlzAgQMHYDAYYDAYkJOTg7KyMphMJuh0OgQGBqJHjx7Q6/XQ6/WIioq6JQwvXryINm3awGQyMTSJbMDgVKDq8CwrK4OXlxfOnz+Pli1bwmQyYdOmTVi0aBG+//57AEDLli2h1+sRGRmJhg0bwtvbG5WVlbh48SIOHTqErKwsVFRUICAgAOPGjUNCQgI6deoEAHjrrbfw6quvAgDi4uIYmkR1JUiRMjIyRP369QUAMXfuXLFgwQLRqlUrAUD06dNHfPbZZyI/P/+u61RVVYmsrCzxyiuviHvvvVcAEHFxcWL//v2iZcuW1p9LS0td8FsRqQNPnAq2d+9e9O3bF0IIGI1GTJgwAVOnTkX37t3tWq+yshJff/013nnnHRw/fhwWiwUxMTHYunUrT5pENuCLQwolhMDBgwchhEDz5s3x448/YunSpXaHJgDodDqMGjUKBoMBr732Gry8vHDp0iXk5uZKNziRB2BwKpAQAn/7298wffp0PPfcczhx4gQefvhhydb38fHB3LlzYTAYoNVq8fDDD2Pfvn2SrU+kdqzqCiOEwMyZM7FgwQIsXLgQU6dOdep+165dw6BBg3DkyBHs2LEDUVFRTt2PSA0YnArz3nvv4e9//zs+/vhjvPDCCy7Zs7S0FP3798fJkydx4MABtG/f3iX7ErkrBqeCHDlyBFFRUZg5cybeeecdl+599epV6PV6BAcH44cffqjxCSYiqonBqRBVVVXo1asXzGYzMjMzUa9ePZfPsGPHDvTt2xcfffQRXnzxRZfvT+QueKxQiHnz5uHo0aNYsWKFLKEJ3HwTfGJiImbNmoWzZ8/KMgORO+CJUwGKi4vRunVrTJkyBe+9956ss5SUlKBDhw544oknsGjRIllnIVIqnjgV4PPPP0dpaSmmTZsm9yjw9/fHc889h1WrVuHGjRtyj0OkSAxOmQkhkJycjCFDhqBNmzZyjwMAmDx5MsrLy7F69Wq5RyFSJAanzDIzM5GdnY2EhAS5R7EKCgrC0KFDXfbVHUTuhsEps4yMDOh0OsTFxdl0v08++QQNGzaEyWSy3lZSUgIfH59bPmW0a9cuaDSaGhcsvps///nPOHLkCEpLS22ai8gTMDhlZjAY0K1bN5u/GC0uLg4lJSXIzMy03rZr1y60aNECBw8erPHVF+np6WjVqhU6duxY5/X1ej0sFguysrJsmovIEzA4ZWYwGKDX622+X3h4OFq1alXjCvHp6ekYOnQoQkNDkZGRUeN2W0+0nTt3Rr169WAwGGyejUjtGJwyMplMyMnJQbdu3ey6f2xsLHbs2GH9eceOHYiNjUVMTIz1dqPRiL1799ocnPXq1UPnzp1x7Ngxu2YjUjMGp4zKyspgsVjQuHFju+4fGxuLPXv2wGQyobi4GIcPH0Z0dDRiYmKsJ9F9+/ahvLzc5uAEgEaNGqGkpMSu2YjUzFvuATyZ0WgEALs/KRQXF4fS0lIcPHgQV69eRceOHdGsWTPExMRgzJgxKC0tRXp6OoKDg+26cEe9evWsMxLRbxicMtLpdABuXpndHmFhYQgKCsKOHTtw9epVxMTEAABatGiBdu3aYc+ePdbPn9ujsrISTZs2teu+RGrGqi6j+vXrw9vbG1euXLF7jbi4OKSnpyM9PR2xsbHW22NiYpCWloZ9+/bZVdMB4MqVKwgICLB7NiK1YnDKyMvLC5GRkTh8+LDda8TFxWH37t3IysqynjiBm8G5ZMkSVFRU2BWc5eXlOHHihN0vXBGpGYNTZnq93qG3/MTFxaG8vBxhYWFo3ry59faYmBgUFxcjNDTUro9yZmdnw2w22/VWKSK143OcMtPr9Vi5ciUqKirg6+tr8/1DQkJwuwtcBQUF3fb2ujIYDPD29kaXLl3sXoNIrXjilFl0dDRMJhO2bdsm9yg1bNy4Eb169bIrzInUjtfjVIAHH3wQfn5+2L59u9yjAABOnjyJ8PBwrFy5EmPHjpV7HCLF4YlTARITE/H9998jJydH7lEA3LyAyD333IPhw4fLPQqRIjE4FeCpp55C06ZN8f7778s9Ci5duoTly5fj2WefZU0nugMGpwLodDrMnTsXS5cuxffffy/rLC+++CK8vLwwY8YMWecgUjI+x6kQFosF/fr1Q25uLo4ePYqGDRu6fIb169dj2LBhWLt2LUaOHOny/YncBYNTQXJzc9GlSxc89dRTWL58OTQajcv2Pn/+PPR6PR5++GGsX7/epXsTuRtWdQVp164dkpOTsXLlSsyePduh92HaoqCgAPHx8WjQoAGSk5MZmkR3wTfAK8yYMWNw6dIlzJw5EyaTCfPnz3dqkJ0/fx79+/fHjRs3sHv3bjRr1sxpexGpBYNTgWbMmAFvb29Mnz4dp0+fxieffFLj45RS2bZtGyZNmgQfHx/s3LkToaGhku9BpEas6go1bdo0bNiwAXv27EFERATWrl0rWXW/du0ann32WTz22GPo0qULMjIy0KFDB0nWJvIEDE4Fe/zxx3H8+HHEx8dj1KhR6N+/PzZt2gSz2WzXeoWFhZg3bx4iIiKwfv16pKSkYNu2bWjVqpXEkxOpG19VdxPffPMN5s2bhwMHDiA4OBiTJ09GfHw8unXrBj8/vzveLz8/H5mZmfjyyy+xbt06eHl54emnn8Ybb7xh11WTiIjB6XYyMzORnJyMtWvXory8HF5eXoiIiEBkZCT8/f3h4+ODiooKFBQUwGAw4OLFiwCA0NBQJCQkYMKECQgMDJT5tyBybwxON1VZWYljx47BYDAgMzMTOTk5KC8vR1VVFXx9fREYGIgePXpAr9dDr9cjODiYbzMikgiDk4jIRnxxiIjIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQishGDk4jIRgxOIiIbMTiJiGzE4CQistH/Azu5UNmjwMTwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 314.961x314.961 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pgm = PGM(shape=[4, 4])\n",
    "\n",
    "pgm.add_node(daft.Node('C', r\"C\", 2, 4))\n",
    "pgm.add_node(daft.Node('R', r\"R\", 1, 2.5))\n",
    "pgm.add_node(daft.Node('S', r\"S\", 3, 2.5))\n",
    "pgm.add_node(daft.Node('W', r\"W\", 2, 1))\n",
    "\n",
    "\n",
    "pgm.add_edge('C', 'R')\n",
    "pgm.add_edge('C', 'S')\n",
    "pgm.add_edge('S', 'W')\n",
    "pgm.add_edge('R', 'W')\n",
    "\n",
    "pgm.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c514edd",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "(5 pts) Calculate a probability p(C,S,R,W).\n",
    "\n",
    "$$\\begin{equation}\\begin{split}\n",
    "\\sum_{S,R\\in\\{T,F\\}}p(C,S,R,W)&=\\sum_{S,R\\in\\{T,F\\}}p(C=T|S,R)p(S,R|W)p(W)\\\\\n",
    "&=p(C=T|S=T,R=T)p(S=T|R=T)p(W=T)\\\\\n",
    "&\\,\\,+p(C=T|S=T,R=F)p(S=T|R=F)p(W=T)\\\\\n",
    "&\\,\\,+p(C=T|S=F,R=T)p(S=F|R=T)p(W=T)\\\\\n",
    "&\\,\\,+p(C=T|S=F,R=F)p(S=F|R=F)p(W=T)\\\\\n",
    "\\end{split}\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4903cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 27.16%.\n"
     ]
    }
   ],
   "source": [
    "joint_probabilities = [\n",
    "    (0.2 * 0.8 * 0.02),  # P_CtStRtWt\n",
    "    (0.2 * 0.2 * 0.15),  # P_CtStRfWt\n",
    "    (0.8 * 0.8 * 0.17),  # P_CtSfRtWt\n",
    "    (0.8 * 0.2 * 0.96),  # P_CtSfRfWt\n",
    "    # (0.2 * 0.8 * 0.98),  # P_CtStRtWf\n",
    "    # (0.2 * 0.2 * 0.85),  # P_CtStRfWf\n",
    "    # (0.8 * 0.8 * 0.83),  # P_CtSfRtWf\n",
    "    # (0.8 * 0.2 * 0.04),  # P_CtSfRfWf\n",
    "]\n",
    "print(f\"Probability: {round(sum(joint_probabilities) * 100, 4)}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f7b47",
   "metadata": {},
   "source": [
    "## Part C\n",
    "(5 pts) Calculate a probability p(S=T|W=T).\n",
    "\n",
    "$$\\begin{equation}\\begin{split}\n",
    "P(S=T|W=T)&=\\frac{P(W=T|S=T)P(S=T)}{P(W=T)}\\\\\n",
    "&=\\frac{\\sum_{C\\in\\{T,F\\}}P(W=T,R,S=T)}{\\sum_{S,R\\in\\{T,F\\}}P(W=T,S,R)}\n",
    "\\end{split}\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f6d259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 6.5385%.\n"
     ]
    }
   ],
   "source": [
    "# numerator\n",
    "P_WtStRt = 0.02\n",
    "P_WtStRf = 0.15\n",
    "P_WtSt = P_WtStRt + P_WtStRf\n",
    "\n",
    "P_StCt = 0.3\n",
    "P_StCf = 0.2\n",
    "P_St = P_StCt + P_StCf\n",
    "\n",
    "# denominator\n",
    "P_WtSfRt = 0.17\n",
    "P_WtSfRf = 0.96\n",
    "P_Wt = P_WtStRt + P_WtStRf + P_WtSfRt + P_WtSfRf\n",
    "\n",
    "# tying it all together!\n",
    "P_StWt = (P_WtSt * P_St) / (P_Wt)\n",
    "P_StWt\n",
    "print(f\"Probability: {round(P_StWt * 100, 4)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8767335",
   "metadata": {},
   "source": [
    "## Part D\n",
    "(10 pts) Using a provided data table, `GM_train.csv`, train a graphical model using `pgmpy.models.BayesianModel` and report the accuracy. The target is W. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c615eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecff2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>R</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  S  R  W\n",
       "0  0  1  1  0\n",
       "1  0  1  1  0\n",
       "2  1  1  0  0\n",
       "3  0  1  1  0\n",
       "4  1  0  0  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"./GM_train.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa1165",
   "metadata": {},
   "source": [
    "Training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e464cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+---------------------+--------------------+\n",
      "| R    | R(0) | R(0) | R(1)                | R(1)               |\n",
      "+------+------+------+---------------------+--------------------+\n",
      "| S    | S(0) | S(1) | S(0)                | S(1)               |\n",
      "+------+------+------+---------------------+--------------------+\n",
      "| W(0) | 0.56 | 0.65 | 0.46153846153846156 | 0.5517241379310345 |\n",
      "+------+------+------+---------------------+--------------------+\n",
      "| W(1) | 0.44 | 0.35 | 0.5384615384615384  | 0.4482758620689655 |\n",
      "+------+------+------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "model = convert_pgm_to_pgmpy(pgm)\n",
    "model.fit(data_train)\n",
    "print(model.get_cpds(\"W\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be37783",
   "metadata": {},
   "source": [
    "Finally, let's get the training accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8a9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cfe14e896f4f26b5b7f70503095863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = data_train[\"W\"]\n",
    "y_pred = model.predict(data_train.drop(\"W\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93fba21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 57.0%.\n"
     ]
    }
   ],
   "source": [
    "train_acc = metrics.accuracy_score(y_true, y_pred)\n",
    "print(f\"Train Accuracy: {round(train_acc * 100, 4)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babf17c",
   "metadata": {},
   "source": [
    "## Part E\n",
    "(5 pts) Generalize the model trained in **d** using `GM_test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7098c217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819af477c34e409c90e4848fad010f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.0%.\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"./GM_test.csv\")\n",
    "y_test = data_test[\"W\"]\n",
    "y_pred = model.predict(data_test.drop(\"W\", axis=1))\n",
    "test_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {round(test_acc * 100, 4)}%.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5fdb6e7",
   "metadata": {},
   "source": [
    "# Handwriting recognition: (70 pts)\n",
    "Handwriting recognition is a well-studied subject in computer vision and has found wide applications in our daily life (such as USPS mail sorting). In this project, we will explore various machine learning techniques for recognizing handwriting digits. The dataset you will be using is the well-known MINST dataset.\n",
    "\n",
    "(1)\tThe MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "(2)\tBelow is an example of some digits from the MNIST dataset.\n",
    "\n",
    "![Image of MINST](https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp)\n",
    "\n",
    "(3)\tThe goal of this assignment is to build a 10-class classifier to recognize those handwriting digits as accurately as you can.  All the assignments below should use the training data (60K examples) and test data (10 K examples) as given by the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7115b7b9",
   "metadata": {},
   "source": [
    "## Part A\n",
    "(30 pts) Build several non-deep learning based classifiers using all pixels as features for handwriting recognition. You need to use at least **three techniques** we have learned from the class to do the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146daff",
   "metadata": {},
   "source": [
    "### Step 1: Load and Standardize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c67e2c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./mnist-in-csv/mnist_train.csv\")\n",
    "\n",
    "df_test = pd.read_csv(\"./mnist-in-csv/mnist_test.csv\")\n",
    "\n",
    "display(df_train.head())\n",
    "columns = df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81780d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = df_train.drop(\"label\", axis=1), df_test.drop(\"label\", axis=1)\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "y_train, y_test = (\n",
    "    df_train[\"label\"].values,\n",
    "    df_test[\"label\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d5617",
   "metadata": {},
   "source": [
    "### Step 2: Evaluate Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9873497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72936f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/559/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Applications/anaconda3/envs/559/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Applications/anaconda3/envs/559/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>0.9183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>0.8603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_type  Training  Testing\n",
       "0  Nearest Neighbors  0.981917   0.9688\n",
       "1         Linear SVM  0.926200   0.9183\n",
       "2      Decision Tree  0.856900   0.8603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# define list of models to try\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"Decision Tree\",\n",
    "]\n",
    "# instantiate them\n",
    "regressors = [\n",
    "    KNeighborsClassifier(5),\n",
    "    LinearSVC(random_state=42, C=1.0),  # note: C can be decreased to strength regularization\n",
    "    RandomForestClassifier(max_depth=5),\n",
    "]\n",
    "\n",
    "# init a dict of scoring for each model\n",
    "model_results = []\n",
    "\n",
    "# apply each model\n",
    "for name, model in zip(names, regressors):\n",
    "    # record the score\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = metrics.accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    model_results.append(pd.Series({\n",
    "        \"model_type\": name,\n",
    "        \"Training\": train_accuracy, \n",
    "        \"Testing\": test_accuracy,\n",
    "    }))\n",
    "# take a look at the result\n",
    "df = pd.DataFrame(model_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b98827",
   "metadata": {},
   "source": [
    "b.\t(10 pts) In this assignment, we will explore various techniques related to a neural network with hidden layers of more than 3 to solve the 10-class classification problem.\n",
    "\n",
    "Since there are many existing implementations to solve the MINST problem, we need to give some twists to this problem to make it worthwhile to do for our final assignment. (Please refer to the ranking list for MNIST at [http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html).\n",
    "\n",
    "The basic network structure that we are trying to explore is something like the following (i.e., the fully connected deep neural nets). The number of hidden layers and the size of each hidden layer in terms of neurons are left as tuning parameters that you can explore.\n",
    "\n",
    "![Image of NN](https://pimages.toolbox.com/wp-content/uploads/2022/05/18113202/The-Architecture-of-a-Neural-Network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8a08f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "# CNN and MLP architecture\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Rescaling,\n",
    ")\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "# Keras Callbacks\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "# Image Preprocessing\n",
    "from PIL import Image\n",
    "# Optimizing Hyperparameters\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "# Loading Model from JSON file\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08711d77",
   "metadata": {},
   "source": [
    "Now I'll reload the dataset, but in a Tensorflow-y way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "98d21c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "319dd7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df_train = df_train[\"label\"]\n",
    "y_df_train = LabelBinarizer().fit_transform(y_df_train)\n",
    "y_df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "404666de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df_test = df_test[\"label\"]\n",
    "y_df_test = LabelBinarizer().fit_transform(y_df_test)\n",
    "y_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1659dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_train = df_train.drop(\"label\", axis=1) / 255.\n",
    "\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(tf.expand_dims(\n",
    "                # np.array([np.newaxis, X_df_train.values]),\n",
    "                X_df_train.values.reshape(-1, 784),\n",
    "            1), tf.float32),\n",
    "            tf.cast(y_df_train.reshape(-1, 1, 10), tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# optimizes the efficiency of loading training data\n",
    "train_ds_batches = (\n",
    "      train_ds.cache().shuffle(500)\n",
    "      .prefetch(tf.data.AUTOTUNE)).batch(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9cb5f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_test = df_test.drop(\"label\", axis=1) / 255.\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(tf.expand_dims(\n",
    "                # X_df_test.values.reshape(-1, 784),\n",
    "                X_df_test.values.reshape(-1, 784),\n",
    "            1), tf.float32),\n",
    "            tf.cast(y_df_test.reshape(-1, 1, 10), tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# optimizes the efficiency of loading training data\n",
    "test_ds_batches = (\n",
    "      test_ds.cache().shuffle(500)\n",
    "      .prefetch(tf.data.AUTOTUNE)).batch(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182ce18",
   "metadata": {},
   "source": [
    "Let's create a validation set (to make the training easier to monitor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b69e396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 14:40:36.871819: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    }
   ],
   "source": [
    "def is_validation(image, _):\n",
    "    '''marks every 10th sample a part of the validation data'''\n",
    "    return image % 10 == 0\n",
    "\n",
    "\n",
    "def recover_label(_, label):\n",
    "    return label\n",
    "\n",
    "val_ds = (\n",
    "    train_ds_batches.enumerate().filter(is_validation) \\\n",
    "    .map(recover_label)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323f67a",
   "metadata": {},
   "source": [
    "Let's add some helper functions to make the code less repetitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1de1b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to Reduce Repetition\n",
    "def add_conv_layer(model, layer_size, needs_input, kernel_size=None, pool_size=None):\n",
    "    \"\"\"Add a Keras convolutional layer to the model, along with MaxPooling.\n",
    "       Will specify input shape as well if needed.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       need_input(bool): signals if the convolutional layer needs to specify\n",
    "                         the dimensions of the input\n",
    "       kernel_size(tuple): specifies a square matrix to use for kernel dimensions\n",
    "       pool_size(tuple): specifies a square matrix to use in pooling\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # set kernel and pool size\n",
    "    if kernel_size is None:\n",
    "        kernel_size = (3, 3)\n",
    "    if pool_size is None:\n",
    "        pool_size = (2, 2)\n",
    "    # specify input dimension for 1st conv layer\n",
    "    if needs_input is True:\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu',\n",
    "                            input_shape=(...))\n",
    "\n",
    "    else:\n",
    "        # otherwise all other convolutional layers don't need it\n",
    "        conv_layer = Conv2D(layer_size,\n",
    "                            kernel_size=kernel_size,\n",
    "                            activation='relu')\n",
    "    # add Convolutional layer\n",
    "    model.add(conv_layer)  \n",
    "    # add MaxPooling layer\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))  # no learning params\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_dense_layer(model, layer_size, is_output, drop_rate):\n",
    "    \"\"\"Add a multi-layer perceptron to the model\n",
    "       Will specify 'sigmoid' for the final layer.\n",
    "       \n",
    "       Parameters:\n",
    "       model(Model): Neural network in Keras\n",
    "       layer_size(int): number of neurons to go in layer\n",
    "       is_output(bdool): signals if the MLP is the last layer\n",
    "       drop_rate(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # specify activation function\n",
    "    activation = 'relu' if is_output is False else 'softmax'\n",
    "    # add MLP\n",
    "    model.add(Dense(layer_size, activation=activation)) \n",
    "    # Add Dropout layer and Batch Normalization\n",
    "    # else:\n",
    "    if is_output is False:\n",
    "        # model.add(Dense(layer_size, activation=activation)) \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(drop_rate))\n",
    "    return None\n",
    "\n",
    "\n",
    "def compile_model(model, optimizer=None):\n",
    "    \"\"\"Compile the neural network.\n",
    "    \n",
    "       Parameter:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       optimizer(str): specfies the algoritm used to minimize loss\n",
    "       \n",
    "       Returns: None\n",
    "       \n",
    "    \"\"\"\n",
    "    # set the optimizer\n",
    "    if optimizer is None:\n",
    "        optimizer = 'adam'\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Precision(),\n",
    "                           tf.keras.metrics.Recall()])\n",
    "    return None\n",
    "\n",
    "\n",
    "def define_model(units, conv_layers, dense_layers, dropout, num_classes=10):\n",
    "    \"\"\"Define a Sequential model in Keras.\n",
    "    \n",
    "       Parameters:\n",
    "       units(int): number of neurons to go in a layer\n",
    "       conv_layers(int): number of convolutional layers\n",
    "       dense_layers(int): number of MLP\n",
    "       dropout(float): percentage of connections in Dense layer\n",
    "                       to cut off\n",
    "                       \n",
    "       Returns: tf.keras.Sequential: the neural network to train\n",
    "    \n",
    "    \"\"\"\n",
    "    # Instaniate model\n",
    "    model = Sequential()\n",
    "    # Add CNN layers\n",
    "    if conv_layers > 0:\n",
    "        add_conv_layer(model, units, True)\n",
    "        for _ in range(conv_layers - 1):\n",
    "            # add convolutional layers that come after the 1st\n",
    "            add_conv_layer(model, units, False)\n",
    "    # Flatten the data\n",
    "    if conv_layers > 0:\n",
    "        model.add(Flatten())\n",
    "    else:  # if no flattening, tell the model what input shape to expect\n",
    "        model.add(keras.layers.InputLayer(input_shape=(1, 784)))\n",
    "    # Add MLP Layers\n",
    "    for _ in range(dense_layers - 1):\n",
    "        add_dense_layer(model, units, False, dropout)\n",
    "    # add final MLP, for output\n",
    "    add_dense_layer(model, num_classes, True, dropout)\n",
    "    # Compile Model\n",
    "    compile_model(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, train_ds, val_ds,\n",
    "                epochs, callbacks):\n",
    "    \"\"\"Train the Keras model.\n",
    "       \n",
    "       Parameters:\n",
    "       model(keras.Sequential or keras.Model): the model object\n",
    "       train_ds(tf.Dataset): subsection of the dataset for training\n",
    "       val_ds(tf.Dataset): subsection of the dataset for validation\n",
    "       epochs(int): number of forward and back passes for the entire\n",
    "                    dataset through the model\n",
    "       callbacks(List): special Keras functions to improve models\n",
    "       \n",
    "       returns: History.history: a dict containing metrics about model\n",
    "       \n",
    "    \"\"\"\n",
    "    # train the model\n",
    "    history = model.fit(x=train_ds,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=callbacks)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741db1de",
   "metadata": {},
   "source": [
    "Now, let's try out a few quick 'n dirty model  to finally get things moving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c80b7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0d41869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 13s 3ms/step - loss: 1.4917 - accuracy: 0.4611 - precision_56: 0.7710 - recall_56: 0.2352 - val_loss: 0.6850 - val_accuracy: 0.7780 - val_precision_56: 0.8834 - val_recall_56: 0.6177\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.9547 - accuracy: 0.6737 - precision_56: 0.7913 - recall_56: 0.5196 - val_loss: 0.4923 - val_accuracy: 0.8633 - val_precision_56: 0.9007 - val_recall_56: 0.8287\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.8233 - accuracy: 0.7296 - precision_56: 0.8048 - recall_56: 0.6281 - val_loss: 0.4227 - val_accuracy: 0.8850 - val_precision_56: 0.9045 - val_recall_56: 0.8702\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 4s 3ms/step - loss: 0.7409 - accuracy: 0.7693 - precision_56: 0.8291 - recall_56: 0.6964 - val_loss: 0.3328 - val_accuracy: 0.9092 - val_precision_56: 0.9243 - val_recall_56: 0.8995\n",
      "Epoch 5/20\n",
      " 373/1200 [========>.....................] - ETA: 2s - loss: 0.7066 - accuracy: 0.7866 - precision_56: 0.8411 - recall_56: 0.7229"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb Cell 47\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Train the Model (using a generator!)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m epochs, batch_size \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m, \u001b[39m20\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m history \u001b[39m=\u001b[39m train_model(model, train_ds_batches,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                       val_ds, epochs, [tensorboard])\n",
      "\u001b[1;32m/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb Cell 47\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_ds, val_ds, epochs, callbacks)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39m\"\"\"Train the Keras model.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m   \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m \u001b[39m   Parameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m   \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_ds,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zainraza/Downloads/dev/courses/Stevens/CS-559/SyedRaza_HW5/SyedRaza_HW5.ipynb#X65sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:336\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m captures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captures_container\u001b[39m.\u001b[39mget_snapshot()\n\u001b[1;32m    333\u001b[0m \u001b[39m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# only active captures should be saved.\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m lookup_func_key, _ \u001b[39m=\u001b[39m function_context\u001b[39m.\u001b[39;49mmake_cache_key((args, kwargs),\n\u001b[1;32m    337\u001b[0m                                                      captures)\n\u001b[1;32m    338\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mlookup(lookup_func_key, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m concrete_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:133\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    131\u001b[0m   captures \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    132\u001b[0m signature_context \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mInternalTracingContext()\n\u001b[0;32m--> 133\u001b[0m args_signature \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39;49mfrom_value(\n\u001b[1;32m    134\u001b[0m     args, signature_context)\n\u001b[1;32m    135\u001b[0m captures_dict_tracetype \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(\n\u001b[1;32m    136\u001b[0m     captures, signature_context)\n\u001b[1;32m    138\u001b[0m \u001b[39m# TODO(fmuham): Use the actual FunctionType\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:114\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mis_legacy_signature \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(value, trace\u001b[39m.\u001b[39mTraceType):\n\u001b[1;32m    113\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(value, trace\u001b[39m.\u001b[39;49mSupportsTracingProtocol):\n\u001b[1;32m    115\u001b[0m   \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39m__tf_tracing_type__(context)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39m__wrapped__\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/typing.py:1509\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_protocol:\n\u001b[1;32m   1505\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mhasattr\u001b[39m(instance, attr) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m             \u001b[39m# All *methods* can be blocked by setting them to None.\u001b[39;00m\n\u001b[1;32m   1507\u001b[0m             (\u001b[39mnot\u001b[39;00m callable(\u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, attr, \u001b[39mNone\u001b[39;00m)) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m              \u001b[39mgetattr\u001b[39m(instance, attr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1509\u001b[0m             \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m _get_protocol_attrs(\u001b[39mcls\u001b[39;49m)):\n\u001b[1;32m   1510\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__instancecheck__\u001b[39m(instance)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/559/lib/python3.10/typing.py:1417\u001b[0m, in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m base\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGeneric\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1416\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 1417\u001b[0m annotations \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(base, \u001b[39m'\u001b[39;49m\u001b[39m__annotations__\u001b[39;49m\u001b[39m'\u001b[39;49m, {})\n\u001b[1;32m   1418\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(base\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(annotations\u001b[39m.\u001b[39mkeys()):\n\u001b[1;32m   1419\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m attr\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_abc_\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m attr \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m EXCLUDED_ATTRIBUTES:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Choices for the Model Architecture - values arbitrary\n",
    "dense_layers = [6, 5, 4]\n",
    "layer_sizes = [16, 32, 64]\n",
    "conv_layers = [0]  # for right now, I don't want any convolutions\n",
    "\n",
    "# try different combinations!\n",
    "for num_fc_layer in dense_layers:\n",
    "    for size in layer_sizes:\n",
    "        for num_conv_layers in conv_layers:\n",
    "            # name the combo - based on it's architecture, and when it was run\n",
    "            NAME = (\n",
    "                f'{num_conv_layers}-conv-{size}-nodes' +\n",
    "                f'-{num_fc_layer}-dense_layers' + \n",
    "                f'-{int(time.time())}'\n",
    "            )\n",
    "            # Instantiate TensorBoard to visualize model performance\n",
    "            tensorboard = TensorBoard(log_dir=f'./Graph/{NAME}')\n",
    "            # Define Model\n",
    "            model = define_model(size, num_conv_layers, num_fc_layer, 0.2)\n",
    "            # Train the Model (using a generator!)\n",
    "            epochs, batch_size = 20, 20\n",
    "            history = train_model(model, train_ds_batches,\n",
    "                                  val_ds, epochs, [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30aa9d",
   "metadata": {},
   "source": [
    "c.\t(30 pts) This assignment reflects the data collection process.\n",
    "- Hand write 5 styles of your own digits from 0 to 9 on a paper, and make sure your own handwritings are for sure recognizable by yourself. Please take a picture of each digit you write (so you have total 5 x 10 = 50 images), resize and convert it to the same data input format as the MNIST dataset. In other words, you have 50 new data points with labels.\n",
    "- Treat these 50 images as “brand-new” test dataset and run your own ML models from Question a and b on these 50 images and report the achieved test accuracy. Note, the goal for this exercise is not for achieving “high” accuracy, but to show what potential gaps there may be between existing MNIST dataset and your own test dataset, a scenario you would encounter in real life.\n",
    "- Use the following code for the image loading. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Photos\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "rootdir = \n",
    "\n",
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    x_img = np.array([0] * 784)\n",
    "\n",
    "\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            idx = i * 28 + j\n",
    "            x_img[idx] = 255 - img[i][j][0]\n",
    "            \n",
    "    return x_img, img\n",
    "    \n",
    "X_mydigits = []\n",
    "Y_mydigits = []\n",
    "digit_imgs = []\n",
    "\n",
    "# read handwritten digits\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            path = os.path.join(subdir, file)\n",
    "            digit, img = read_img(path)\n",
    "            label = int(os.path.splitext(subdir)[0][-1])\n",
    "            X_mydigits.append(digit)\n",
    "            Y_mydigits.append(label)\n",
    "            digit_imgs.append(img)\n",
    "\n",
    "\n",
    "X_mydigits = np.array(X_mydigits)\n",
    "Y_mydigits = np.array(Y_mydigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing all my images\n",
    "temp_img = ''\n",
    "for i in range(5):\n",
    "    hor = ''\n",
    "    for j in range(10):\n",
    "        idx = i*10 + j\n",
    "        img = digit_imgs[idx]\n",
    "        if j == 0:\n",
    "            hor = img\n",
    "        else:\n",
    "            hor = np.hstack((hor, img))\n",
    "    if i == 0:\n",
    "        temp_img = hor\n",
    "    else:\n",
    "        temp_img = np.vstack((temp_img, hor))\n",
    "\n",
    "plt.imshow(temp_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed5dd4",
   "metadata": {},
   "source": [
    "d.\tIn submission, the following is required for this assignment \n",
    "- Show all 50 images you create with the corresponding labels you intend to assign, \n",
    "- Make a table to show the test accuracy on these 50 images for each ML model you obtained from questions a to c.\n",
    "- Submit in a subfolder with your 50 handwriting dataset in MNIST format. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863570c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('559')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "814950ec8b8c7032d23fac38b059fcb51ad391395255f22f9a4e55af65449f0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
