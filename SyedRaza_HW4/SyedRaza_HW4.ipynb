{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 559 HW 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhnq4YzdybKY"
      },
      "source": [
        "## Question 1 [ 40 Points ]\n",
        "\n",
        "**Support Vector Machines (SVMs)**\n",
        "\n",
        "[25 points ] Download this dataset, split it as a 80% training and 20% test set. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import model_selection\n",
        "\n",
        "# the link to the Iris dataset in the hw doc didn't work,\n",
        "# so I'll be importing through Scikit-learn directly\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "\n",
        "X = np.array(iris.data)\n",
        "y = np.array(iris.target).reshape(-1,1)\n",
        "iris_df = pd.DataFrame(data=np.column_stack([X, y]))\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4\n",
              "0  5.1  3.5  1.4  0.2  0.0\n",
              "1  4.9  3.0  1.4  0.2  0.0\n",
              "2  4.7  3.2  1.3  0.2  0.0\n",
              "3  4.6  3.1  1.5  0.2  0.0\n",
              "4  5.0  3.6  1.4  0.2  0.0"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 2.])"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris_df[4].unique() # how many classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(quickly doing feature scaling before any further modeling development)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement the support vector algorithm from scratch using Numpy and Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of simplicity, let's start by seeing if we can build a classifier that can at least to binary classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "I49gdoFFyR7D"
      },
      "outputs": [],
      "source": [
        "class BinarySVC:\n",
        "    \"\"\"\n",
        "    Credit to this presentation by Patrick Loeber\n",
        "    for helping me on the code: \n",
        "    https://www.youtube.com/watch?v=UX0f9BNBcsY\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, epochs=1000):\n",
        "        self.lr = learning_rate  # used for optimization\n",
        "        self.regularizer = lambda_param  # used for regularization\n",
        "        self.epochs = epochs\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def _linear_output(self, X):\n",
        "        return np.dot(X, self.w) - self.b\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_samples, n_features = X_train.shape\n",
        "\n",
        "        binary_labels = np.where(y_train <= 0, -1, 1)\n",
        "\n",
        "        # init the params of the model\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        # using gradient descent\n",
        "        for _ in range(self.epochs):\n",
        "            for index, sample in enumerate(X_train):\n",
        "                is_positive_class = binary_labels[index] * (self._linear_output(sample)) >= 1\n",
        "                \n",
        "                # derivatives used to update the weights\n",
        "                if is_positive_class is True:\n",
        "                    self.w -= self.lr * (2 * self.regularizer * self.w)\n",
        "                else:  # belongs to the negative class\n",
        "                    self.w -= self.lr * (\n",
        "                        2 * self.regularizer * self.w - \n",
        "                        np.dot(sample.reshape(-1, 1), binary_labels[index])\n",
        "                    )\n",
        "                    self.b -= self.lr * binary_labels[index]\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"For the purpose of binary classification, we only output +1 or -1.\"\"\"\n",
        "        return np.sign(self._linear_output(X))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_model = BinarySVC()\n",
        "custom_model.fit(X_train_scaled, y_train)\n",
        "metrics.accuracy_score(y_test, custom_model.predict(X_test_scaled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! At least the code works.\n",
        "As we can see though, the accuracy is not great - this is an expected problem though, since only one of the labels in our actual dataset (0, 1, and 2) and can be outputted by our model implementation (which predicts only -1 and 1). \n",
        "\n",
        "Therefore, we'll have to do a little extra work to make this a proper, *multiclass* classifier. Let's go ahead and write an OVR classifier next (since that's the most popular scheme for multiclass SVCs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OneVersusRestSVC:\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, epochs=1000):\n",
        "        self.lr = learning_rate  # used for optimization\n",
        "        self.regularizer = lambda_param  # used for regularization\n",
        "        self.epochs = epochs\n",
        "        self.classifiers = dict()\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        # A: for each class, train a classifier\n",
        "        labels = np.unique(y_train)\n",
        "        for positive_label in labels:\n",
        "            # transform the n-1 \"non-positive\" labels to all be -1\n",
        "            y_train_transformed = np.where(y_train != positive_label, -1, 1)\n",
        "            binary_model = BinarySVC()\n",
        "            binary_model.fit(X_train, y_train_transformed)\n",
        "            # save this trained model for later predictions\n",
        "            self.classifiers[positive_label] = binary_model\n",
        "\n",
        "    def predict(self, X):\n",
        "        # get all the models to \"vote\" on if the sample(s) fall in their positive class\n",
        "        votes = dict()\n",
        "        for pos_label, model in self.classifiers.items():\n",
        "            votes[pos_label] = model._linear_output(X)\n",
        "\n",
        "        # decide what final label ought to be\n",
        "        y_pred_final = np.zeros(X.shape[0])\n",
        "\n",
        "        for index in range(y_pred_final.shape[0]):\n",
        "            # linear search for the most confident prediction\n",
        "            strongest_pred_confidence, pos_label_of_strongest = -1, None\n",
        "            for pos_label, predictions in votes.items():\n",
        "                model_pred = predictions[index]\n",
        "                if abs(model_pred) > strongest_pred_confidence:\n",
        "                    strongest_pred = model_pred\n",
        "                    pos_label_of_strongest = pos_label\n",
        "             # now, we see if we can actually use that model's positive class label, or go to the others\n",
        "            if model_pred > 0:\n",
        "                y_pred_final[index] = pos_label_of_strongest\n",
        "            else:  # model_pred < 0\n",
        "                # need to take the positive label of one of the other classifiers\n",
        "                candidate_classes = [\n",
        "                    pos_label for pos_label in self.classifiers.keys()\n",
        "                    if pos_label != pos_label_of_strongest\n",
        "                ]\n",
        "                # another search, narrowed down to JUST these classes\n",
        "                labels_and_preds = [\n",
        "                    (pos_label, predictions[index])\n",
        "                    for pos_label, predictions in votes.items()\n",
        "                    if pos_label != pos_label_of_strongest\n",
        "                ]\n",
        "                # take the max of these\n",
        "                labels_and_preds.sort(reverse=True, key=lambda label_pred_tuple: label_pred_tuple[1])\n",
        "                most_likely_label, _ = labels_and_preds[0]\n",
        "                y_pred_final[index] = most_likely_label\n",
        "\n",
        "        # all done!\n",
        "        return y_pred_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[10 points ] Report the accuracies for the train and test sets. Comment on whether your model has overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy of OVR Classifier: 88.3333%.\n",
            "Test Accuracy of OVR Classifier: 90.0%.\n"
          ]
        }
      ],
      "source": [
        "custom_model2 = OneVersusRestSVC()\n",
        "custom_model2.fit(X_train_scaled, y_train)\n",
        "\n",
        "train_accuracy = metrics.accuracy_score(y_train, custom_model2.predict(X_train_scaled))\n",
        "print(f\"Train Accuracy of OVR Classifier: {round(train_accuracy * 100, 4)}%.\")\n",
        "\n",
        "test_accuracy = metrics.accuracy_score(y_test, custom_model2.predict(X_test_scaled))\n",
        "print(f\"Test Accuracy of OVR Classifier: {round(test_accuracy * 100, 4)}%.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cowabunga! The accuracy of the OVR classifier is indeed much better than that of the initial binary support vector classifier above (probably because it is essentially an ensemble).\n",
        "\n",
        "Also, it is hard to tell if the model has started overfitting. Although we do have a noticeable difference in the train and testing accuracies, it is less than 2% and the test accuracy is higher, which suggests that the model is still doing OK at generalizing to the test dataset. Overall, I would say the model is not yet overfit (although if I had more time I would definitely like to investigate this further using K-fold cross-validation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[5 points] Test your model performance with the scikit-learn model. Comment on the difference in accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "INzXYmZWzrFg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy of Scikit-learn Classifier: 98.3333%.\n",
            "Test Accuracy of Scikit-learn Classifier: 96.6667%.\n"
          ]
        }
      ],
      "source": [
        "sklearn_svc = SVC(\n",
        "    decision_function_shape='ovr',\n",
        "    kernel='linear',  # because we're also using a linear model\n",
        "    max_iter=1000,\n",
        "    C=1.0,  # left at the default value\n",
        "    random_state=0   \n",
        ")\n",
        "sklearn_svc.fit(X_train_scaled, np.squeeze(y_train))\n",
        "\n",
        "train_accuracy = metrics.accuracy_score(y_train, sklearn_svc.predict(X_train_scaled))\n",
        "print(f\"Train Accuracy of Scikit-learn Classifier: {round(train_accuracy * 100, 4)}%.\")\n",
        "\n",
        "test_accuracy = metrics.accuracy_score(y_test, sklearn_svc.predict(X_test_scaled))\n",
        "print(f\"Test Accuracy of Scikit-learn Classifier: {round(test_accuracy * 100, 4)}%.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outrageous! So it appears that using an OVR classifier from Scikit-learn, we achieve noticeably higher accuracies on both train/test data. In my opinion, one likely explanation for this difference is because the Scikit-learn model is based off `libsvm`, which is capable of using the dual representation approach to solve SVC problems. This is very cool to see. Also, the `sklearn` model also has a more expected result, of having a higher accuracy on the training data than for the test data. It is still not that huge though, so I would say it hasn't quite overfitted the dataset just yet (but it's probably very close to)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES4uUFwXz-aX"
      },
      "source": [
        "## Question 2 [ 40 Points ]\n",
        "\n",
        "**Decision Trees**\n",
        "\n",
        "a. [5 points] Complete the `test_split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "kDRZCShz45P3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "FqI3dUn-z95m"
      },
      "outputs": [],
      "source": [
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\t# move all nodes that are true to the left, false to the right\n",
        "\t\tif row[index] >= value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:  # row[index] < value\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b. [5 points] Complete the `gini_index` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "q338FeZs0p51"
      },
      "outputs": [],
      "source": [
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, classes):\n",
        "\t\"\"\"\n",
        "\tUsing the calculation approach described here by Josh Gordon:\n",
        "\thttps://youtu.be/LDRbO9a6XPU?t=354\n",
        "\t\"\"\"\n",
        "\t# count all samples at split point\n",
        "\tleft_group, right_group = groups\n",
        "\tn_instances = len(left_group) + len(right_group)\n",
        "\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tif len(group) > 0:  # protect against ZeroDivisionError\n",
        "\t\t\tnum_classes_in_group = len(set(row[-1] for row in group))\n",
        "\t\t\tuncertainty = 1 - (1 / num_classes_in_group)\n",
        "\t\t\tgini += (len(group) / n_instances) * uncertainty\n",
        "\treturn gini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "c. [5 points] Complete the `get_split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "PL6EsIaM05EJ"
      },
      "outputs": [],
      "source": [
        "def get_split(dataset):\n",
        "\t\"\"\"Find the best split point by iterating over every feature / value\n",
        "    and calculating the information gain.\"\"\"\n",
        "\tunique_labels = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\n",
        "\tfor feature_index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\trow_val = row[feature_index]\n",
        "\t\t\tgroups = test_split(feature_index, row[feature_index], dataset) \n",
        "\t\t\tgini = gini_index(groups, unique_labels)\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = (\n",
        "\t\t\t\t\tfeature_index, row_val, gini, groups\n",
        "\t\t\t\t)\n",
        "        \n",
        "\treturn {'index': b_index, 'value': b_value, 'groups': b_groups}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "cb_s3CsC1aGV"
      },
      "outputs": [],
      "source": [
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "d. [15 points] Complete the `split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "0Fv9McfA1cuP"
      },
      "outputs": [],
      "source": [
        "# Create child splits for a node or make terminal\n",
        "#Hint : Just call the to_terminal and get_split functions defined above. \n",
        "\n",
        "def split(node, max_depth, min_size, depth):\n",
        "\tleft, right = node['groups']\n",
        "\tdel(node['groups'])\n",
        " \n",
        "\t# check for a no split\n",
        "\tif not left or not right:\n",
        "\t\tnode['left'] = node['right'] = to_terminal(left)\n",
        "\t\treturn\n",
        "\t# check for max depth\n",
        "\tif depth >= max_depth:\n",
        "\t\tnode['left'], node['right'] = (\n",
        "\t\t\tto_terminal(left), \n",
        "\t\t\tto_terminal(right)\n",
        "\t\t)\n",
        "\t\treturn\n",
        "\n",
        "\t# process left child\n",
        "\tif len(left) <= min_size:\n",
        "\t\tnode['left'] = to_terminal(left)\n",
        "\telse:\n",
        "\t\tnode['left'] = get_split(right)\n",
        "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
        "  \n",
        "\t# process right child\n",
        "\tif len(right) <= min_size:\n",
        "\t\tnode['right'] = to_terminal(right)\n",
        "\telse:\n",
        "\t\tnode['right'] = get_split(right)\n",
        "\t\tsplit(node['right'], max_depth, min_size, depth+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "KQiNy9NE2IoJ"
      },
      "outputs": [],
      "source": [
        "# Build a decision tree\n",
        "def build_tree(train, max_depth, min_size):\n",
        "\troot = get_split(train)\n",
        "\tsplit(root, max_depth, min_size, 1)\n",
        "\treturn root"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "e. [10 points] Print the tree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "rSYBf-DQ2LYs"
      },
      "outputs": [],
      "source": [
        "# Print a decision tree\n",
        "def print_tree(node, depth=0):\n",
        "\tif isinstance(node, dict):\n",
        "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
        "\t\tprint_tree(node['left'], depth+1)\n",
        "\t\tprint_tree(node['right'], depth+1)\n",
        "\telse:\n",
        "\t\tprint('%s[%s]' % ((depth*' ', node)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "MkuT-7SY40Yu"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "\n",
        "X = np.array(iris.data)\n",
        "y = np.array(iris.target).reshape(-1,1)\n",
        "\n",
        "data = np.append(X,y,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "42ivIbmh2j5Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[X3 < 3.000]\n",
            " [1.0]\n",
            " [0.0]\n"
          ]
        }
      ],
      "source": [
        "tree = build_tree(data, 1, 1)\n",
        "print_tree(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAEFoJMP70So"
      },
      "source": [
        "## Question 3 [ 20 Points ]\n",
        "\n",
        "**Random Forests and Boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_names = [\n",
        "    \"buying\", \"maint\", \"doors\",\n",
        "    \"persons\", \"lug_boot\", \"safety\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U1feyKIo73h5"
      },
      "outputs": [],
      "source": [
        "car_df = pd.read_csv(\n",
        "    './car/car.data',\n",
        "    sep=\",\", usecols=list(range(0, 6)), names=col_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buying</th>\n",
              "      <th>maint</th>\n",
              "      <th>doors</th>\n",
              "      <th>persons</th>\n",
              "      <th>lug_boot</th>\n",
              "      <th>safety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  buying  maint doors persons lug_boot safety\n",
              "0  vhigh  vhigh     2       2    small    low\n",
              "1  vhigh  vhigh     2       2    small    med\n",
              "2  vhigh  vhigh     2       2    small   high\n",
              "3  vhigh  vhigh     2       2      med    low\n",
              "4  vhigh  vhigh     2       2      med    med"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "car_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = col_names[:-1]\n",
        "target = [col_names[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing & Splitting Data \n",
        "\n",
        "The approach I'll go with here is that because all the features are *technically* categorical, I'll one-hot encode them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics, model_selection\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_data = dict()\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "for feat in features:\n",
        "    input_feat = car_df[feat].values.reshape(-1, 1)\n",
        "    encoded_feat = enc.fit_transform(input_feat).toarray()\n",
        "    encoded_data[feat] = encoded_feat\n",
        "\n",
        "X = np.column_stack(list(\n",
        "    encoded_data.values()\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the target column, I'll merely use sparse integer encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = car_df[\"safety\"].unique().tolist()\n",
        "convert_to_int = lambda label: classes.index(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = car_df[\"safety\"].transform(convert_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Comparing Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First model - Random Forest coming right up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Train Accuracy: 100%\n",
            "Random Forest Test Accuracy: 28.3237%\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=1, \n",
        "    random_state=0, oob_score=True).fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Train Accuracy: {round(rf_clf.oob_score * 100, 4)}%\")\n",
        "print(f\"Random Forest Test Accuracy: {round(test_accuracy * 100, 4)}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second model: Gradient Boosting, anyone?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosted Classifier Train Accuracy: 36.5412%\n",
            "Gradient Boosted Classifier Test Accuracy: 20.5202%\n"
          ]
        }
      ],
      "source": [
        "grad_boost_clf = GradientBoostingClassifier(\n",
        "    n_estimators=100, learning_rate=1.0,\n",
        "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "# get preds so we can eval accuracy\n",
        "y_pred = grad_boost_clf.predict(X_train)\n",
        "train_accuracy = metrics.accuracy_score(y_train, y_pred)\n",
        "print(f\"Gradient Boosted Classifier Train Accuracy: {round(train_accuracy * 100, 4)}%\")\n",
        "\n",
        "y_pred = grad_boost_clf.predict(X_test)\n",
        "test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosted Classifier Test Accuracy: {round(test_accuracy * 100, 4)}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see from above, the Random Forest classifier outperforms the Gradient Boosted by ~8% on the test dataset, when both were given the same 5 one-hot encoded features and hyperparameters for `n_estimators` and `max_depth`.\n",
        "\n",
        "Both model have higher train accuracies than their respective test accuracies, which suggests both have started overfitting. However, it appears to be much more severe in the case of the Random Forest, which has a perfect score for training accuracy (100%), vs. the ~36.54% for the Gradient Boosted tree."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "559",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "814950ec8b8c7032d23fac38b059fcb51ad391395255f22f9a4e55af65449f0a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
