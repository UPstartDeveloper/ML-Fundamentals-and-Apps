{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 559 HW 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhnq4YzdybKY"
      },
      "source": [
        "## Question 1 [ 40 Points ]\n",
        "\n",
        "**Support Vector Machines (SVMs)**\n",
        "\n",
        "[25 points ] Download this dataset, split it as a 80% training and 20% test set. and implement the support vector algorithm from scratch using Numpy and Pandas.\n",
        "\n",
        "[10 points ] Report the accuracies for the train and test sets. Comment on whether your model has overfit.\n",
        "\n",
        "[5 points] Test your model performance with the scikit-learn model. Comment on the difference in accuracy. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I49gdoFFyR7D"
      },
      "outputs": [],
      "source": [
        "class SVM():\n",
        "    def __init__(self):\n",
        "        #Fill it in\n",
        "        ...\n",
        "\n",
        "    def fit(self):\n",
        "        #Fill it in\n",
        "        ...\n",
        "  \n",
        "    def predict(self):\n",
        "        #Fill it in\n",
        "        ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INzXYmZWzrFg"
      },
      "outputs": [],
      "source": [
        "model = SVM()\n",
        "model.fit('Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcdbdv0Sz3Xz"
      },
      "source": [
        "Training accuracy : \n",
        "\n",
        "Test accuracy : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES4uUFwXz-aX"
      },
      "source": [
        "## Question 2 [ 40 Points ]\n",
        "\n",
        "**Decision Trees**\n",
        "\n",
        "a. [5 points] Complete the `test_split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "kDRZCShz45P3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "FqI3dUn-z95m"
      },
      "outputs": [],
      "source": [
        "# Split a dataset based on an attribute and an attribute value\n",
        "def test_split(index, value, dataset):\n",
        "\tleft, right = list(), list()\n",
        "\tfor row in dataset:\n",
        "\t\t# move all nodes that are true to the left, false to the right\n",
        "\t\tif row[index] >= value:\n",
        "\t\t\tleft.append(row)\n",
        "\t\telse:  # row[index] < value\n",
        "\t\t\tright.append(row)\n",
        "\treturn left, right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b. [5 points] Complete the `gini_index` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "q338FeZs0p51"
      },
      "outputs": [],
      "source": [
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, classes):\n",
        "\t\"\"\"\n",
        "\tUsing the calculation approach described here:\n",
        "\thttps://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
        "\t\"\"\"\n",
        "\t# count all samples at split point\n",
        "\tleft_group, right_group = groups\n",
        "\tn_instances = len(left_group) + len(right_group)\n",
        "\n",
        "\t# sum weighted Gini index for each group\n",
        "\tgini = 0.0\n",
        "\tfor group in groups:\n",
        "\t\tif len(group) > 0:  # protect against ZeroDivisionError\n",
        "\t\t\tnum_classes_in_group = len(set(row[-1] for row in group))\n",
        "\t\t\tuncertainty = 1 - (1 / num_classes_in_group)\n",
        "\t\t\tgini += (len(group) / n_instances) * uncertainty\n",
        "\treturn gini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "c. [5 points] Complete the `get_split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "PL6EsIaM05EJ"
      },
      "outputs": [],
      "source": [
        "def get_split(dataset):\n",
        "\t\"\"\"Find the best split point by iterating over every feature / value\n",
        "    and calculating the information gain.\"\"\"\n",
        "\tunique_labels = list(set(row[-1] for row in dataset))\n",
        "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "\n",
        "\tfor feature_index in range(len(dataset[0])-1):\n",
        "\t\tfor row in dataset:\n",
        "\t\t\trow_val = row[feature_index]\n",
        "\t\t\tgroups = test_split(feature_index, row[feature_index], dataset) \n",
        "\t\t\tgini = gini_index(groups, unique_labels)\n",
        "\t\t\tif gini < b_score:\n",
        "\t\t\t\tb_index, b_value, b_score, b_groups = (\n",
        "\t\t\t\t\tfeature_index, row_val, gini, groups\n",
        "\t\t\t\t)\n",
        "        \n",
        "\treturn {'index': b_index, 'value': b_value, 'groups': b_groups}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "cb_s3CsC1aGV"
      },
      "outputs": [],
      "source": [
        "# Create a terminal node value\n",
        "def to_terminal(group):\n",
        "\toutcomes = [row[-1] for row in group]\n",
        "\treturn max(set(outcomes), key=outcomes.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "d. [15 points] Complete the `split` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "0Fv9McfA1cuP"
      },
      "outputs": [],
      "source": [
        "# Create child splits for a node or make terminal\n",
        "#Hint : Just call the to_terminal and get_split functions defined above. \n",
        "\n",
        "def split(node, max_depth, min_size, depth):\n",
        "\tleft, right = node['groups']\n",
        "\tdel(node['groups'])\n",
        " \n",
        "\t# check for a no split\n",
        "\tif not left or not right:\n",
        "\t\tnode['left'] = node['right'] = to_terminal(left)\n",
        "\t\treturn\n",
        "\t# check for max depth\n",
        "\tif depth >= max_depth:\n",
        "\t\tnode['left'], node['right'] = (\n",
        "\t\t\tto_terminal(left), \n",
        "\t\t\tto_terminal(right)\n",
        "\t\t)\n",
        "\t\treturn\n",
        "\n",
        "\t# process left child\n",
        "\tif len(left) <= min_size:\n",
        "\t\tnode['left'] = to_terminal(left)\n",
        "\telse:\n",
        "\t\tnode['left'] = get_split(right)\n",
        "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
        "  \n",
        "\t# process right child\n",
        "\tif len(right) <= min_size:\n",
        "\t\tnode['right'] = to_terminal(right)\n",
        "\telse:\n",
        "\t\tnode['right'] = get_split(right)\n",
        "\t\tsplit(node['right'], max_depth, min_size, depth+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "KQiNy9NE2IoJ"
      },
      "outputs": [],
      "source": [
        "# Build a decision tree\n",
        "def build_tree(train, max_depth, min_size):\n",
        "\troot = get_split(train)\n",
        "\tsplit(root, max_depth, min_size, 1)\n",
        "\treturn root"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "e. [10 points] Print the tree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "rSYBf-DQ2LYs"
      },
      "outputs": [],
      "source": [
        "# Print a decision tree\n",
        "def print_tree(node, depth=0):\n",
        "\tif isinstance(node, dict):\n",
        "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
        "\t\tprint_tree(node['left'], depth+1)\n",
        "\t\tprint_tree(node['right'], depth+1)\n",
        "\telse:\n",
        "\t\tprint('%s[%s]' % ((depth*' ', node)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "MkuT-7SY40Yu"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "\n",
        "X = np.array(iris.data)\n",
        "y = np.array(iris.target).reshape(-1,1)\n",
        "\n",
        "data = np.append(X,y,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "42ivIbmh2j5Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[X3 < 3.000]\n",
            " [1.0]\n",
            " [0.0]\n"
          ]
        }
      ],
      "source": [
        "tree = build_tree(data, 1, 1)\n",
        "print_tree(tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAEFoJMP70So"
      },
      "source": [
        "## Question 3 [ 20 Points ]\n",
        "\n",
        "**Random Forests and Boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_names = [\n",
        "    \"buying\", \"maint\", \"doors\",\n",
        "    \"persons\", \"lug_boot\", \"safety\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "U1feyKIo73h5"
      },
      "outputs": [],
      "source": [
        "car_df = pd.read_csv(\n",
        "    './car/car.data',\n",
        "    sep=\",\", usecols=list(range(0, 6)), names=col_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buying</th>\n",
              "      <th>maint</th>\n",
              "      <th>doors</th>\n",
              "      <th>persons</th>\n",
              "      <th>lug_boot</th>\n",
              "      <th>safety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  buying  maint doors persons lug_boot safety\n",
              "0  vhigh  vhigh     2       2    small    low\n",
              "1  vhigh  vhigh     2       2    small    med\n",
              "2  vhigh  vhigh     2       2    small   high\n",
              "3  vhigh  vhigh     2       2      med    low\n",
              "4  vhigh  vhigh     2       2      med    med"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "car_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = col_names[:-1]\n",
        "target = [col_names[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing & Splitting Data \n",
        "\n",
        "The approach I'll go with here is that because all the features are *technically* categorical, I'll one-hot encode them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics, model_selection\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_data = dict()\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "for feat in features:\n",
        "    input_feat = car_df[feat].values.reshape(-1, 1)\n",
        "    encoded_feat = enc.fit_transform(input_feat).toarray()\n",
        "    encoded_data[feat] = encoded_feat\n",
        "\n",
        "X = np.column_stack(list(\n",
        "    encoded_data.values()\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the target column, I'll merely use sparse integer encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = car_df[\"safety\"].unique().tolist()\n",
        "convert_to_int = lambda label: classes.index(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = car_df[\"safety\"].transform(convert_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and Comparing Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First model - Random Forest coming right up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Train Accuracy: 100%\n",
            "Random Forest Test Accuracy: 28.3237%\n"
          ]
        }
      ],
      "source": [
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=1, \n",
        "    random_state=0, oob_score=True).fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Train Accuracy: {round(rf_clf.oob_score * 100, 4)}%\")\n",
        "print(f\"Random Forest Test Accuracy: {round(test_accuracy * 100, 4)}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second model: Gradient Boosting, anyone?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosted Classifier Train Accuracy: 36.5412%\n",
            "Gradient Boosted Classifier Test Accuracy: 20.5202%\n"
          ]
        }
      ],
      "source": [
        "grad_boost_clf = GradientBoostingClassifier(\n",
        "    n_estimators=100, learning_rate=1.0,\n",
        "    max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "# get preds so we can eval accuracy\n",
        "y_pred = grad_boost_clf.predict(X_train)\n",
        "train_accuracy = metrics.accuracy_score(y_train, y_pred)\n",
        "print(f\"Gradient Boosted Classifier Train Accuracy: {round(train_accuracy * 100, 4)}%\")\n",
        "\n",
        "y_pred = grad_boost_clf.predict(X_test)\n",
        "test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosted Classifier Test Accuracy: {round(test_accuracy * 100, 4)}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see from above, the Random Forest classifier outperforms the Gradient Boosted by ~8% on the test dataset, when both were given the same 5 one-hot encoded features and hyperparameters for `n_estimators` and `max_depth`.\n",
        "\n",
        "Both model have higher train accuracies than their respective test accuracies, which suggests both have started overfitting. However, it appears to be much more severe in the case of the Random Forest, which has a perfect score for training accuracy (100%), vs. the ~36.54% for the Gradient Boosted tree."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "559",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "814950ec8b8c7032d23fac38b059fcb51ad391395255f22f9a4e55af65449f0a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
